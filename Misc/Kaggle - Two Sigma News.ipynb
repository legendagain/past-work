{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3dc56e38d713550d25a93439c1100a8c92af8ac9"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from hyperopt import STATUS_OK, hp, tpe, Trials, fmin\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.util import ngrams\n",
    "import nltk\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from kaggle.competitions import twosigmanews\n",
    "# You can only call make_env() once, so don't lose it!\n",
    "env = twosigmanews.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c20fa6deeac9d374c98774abd90bdc76b023ee63"
   },
   "outputs": [],
   "source": [
    "(market_train_df, news_train_df) = env.get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "832c0d8fd939e1c68c02b9921de89ddc74704be6"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "grp_market_train = market_train_df.groupby('time')\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "avgClose = grp_market_train['close'].mean()\n",
    "ax1.plot(avgClose)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "avgVolume = grp_market_train['volume'].mean()\n",
    "ax2.plot(avgVolume, color='red', alpha=.4)\n",
    "\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8056b881707072c379ad2e89b9c59c3c041a2ab7"
   },
   "source": [
    "## Main Loop\n",
    "Let's loop through all the days and make our random predictions.  The `days` generator (returned from `get_prediction_days`) will simply stop returning values once you've reached the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "65ebf9b711f46d7069d34ac8e313535391b2c67d"
   },
   "outputs": [],
   "source": [
    "market_obs = market_train_df\n",
    "news_obs = news_train_df\n",
    "\n",
    "testing = False\n",
    "if (testing):\n",
    "    market_obs = market_obs[market_obs.time.dt.year == 2007]\n",
    "    news_obs = news_obs[news_obs.time.dt.year == 2007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "abce813f58cb3cd51ce18076345d92558a44223d"
   },
   "outputs": [],
   "source": [
    "# LabelEncoder will be available outside of function\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# this function engineers features and combines both datasets into one\n",
    "def process_data(market_obs, news_obs, actual=False, all_asset_codes=None):\n",
    "    news_obs['timeKey'] = news_train_df.time.apply(lambda x: datetime.datetime(x.year, x.month, x.day, 22, tzinfo=pytz.utc))\n",
    "    \n",
    "    # should find a way to update weekend news to market-open days\n",
    "    # https://stackoverflow.com/questions/47184507/groupby-and-weighted-average\n",
    "    newsGrp = news_obs.groupby(['timeKey', 'assetName'])\n",
    "    if (testing):\n",
    "        sentimentMetrics = [[0]*newsGrp.size(), [0]*newsGrp.size(), [0]*newsGrp.size()]\n",
    "    else:\n",
    "        #sentimentMetrics = newsGrp.apply(lambda x: x[['sentimentNegative', 'sentimentPositive', 'sentimentWordCount']]\n",
    "        #                                             .multiply(x['relevance'], axis=0).sum() / x['relevance'].sum())\n",
    "        sentimentMetrics = [newsGrp.apply(lambda x: np.average(x['sentimentNegative'], weights=x['relevance'])),\n",
    "                            newsGrp.apply(lambda x: np.average(x['sentimentPositive'], weights=x['relevance'])),\n",
    "                            newsGrp.apply(lambda x: np.average(x['sentimentWordCount'], weights=x['relevance']))]\n",
    "        \n",
    "    sentimentDf = pd.concat(sentimentMetrics, axis=1,\n",
    "                        keys=['sentimentNegative','sentimentPositive','sentimentWordCount']).reset_index()\n",
    "    sentimentDf.rename(columns={'timeKey': 'time'}, inplace=True)\n",
    "    \n",
    "    # merge data and engineer features\n",
    "    if (all_asset_codes is None):\n",
    "        le.fit(market_obs['assetCode'])\n",
    "    else:\n",
    "        le.fit(all_asset_codes)\n",
    "    data = pd.merge(market_obs, sentimentDf, how='left', on=['time','assetName'])\n",
    "    data['dayofweek'], data['month'] = data.time.dt.dayofweek, data.time.dt.month\n",
    "    data['closedHigher'] = data.open > data.close\n",
    "    data['assetCode'] = le.transform(data['assetCode']) \n",
    "    \n",
    "    # segment into x and y DataFrames\n",
    "    if (actual):\n",
    "        x = data.drop(['time', 'assetName'], axis=1)\n",
    "        return (x)\n",
    "    else:\n",
    "        x = data.drop(['returnsOpenNextMktres10', 'time', 'assetName'], axis=1)\n",
    "        y = data['returnsOpenNextMktres10']\n",
    "        return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "786c96e930dc8d98a0be2d51eee548399f3423dd"
   },
   "outputs": [],
   "source": [
    "categorical_cols = ['assetCode', 'dayofweek', 'month', 'closedHigher', 'universe']\n",
    "\n",
    "lgb_params = dict(\n",
    "    objective = 'regression_l1',\n",
    "    learning_rate = 0.1,\n",
    "    num_leaves = 3,\n",
    "    max_depth = -1,\n",
    "    min_data_in_leaf = 1000,\n",
    "    bagging_fraction = 0.5,\n",
    "    bagging_freq = 2,\n",
    "    feature_fraction = 0.75,\n",
    "    lambda_l1 = 0.0,\n",
    "    lambda_l2 = 0.0,\n",
    "    metric = 'None', # This will ignore the loss objetive and use sigma_score instead,\n",
    "    seed = 42 # Change for better luck! :)\n",
    ")\n",
    "\n",
    "space = {\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': hp.choice('num_leaves', np.arange(30, 150, dtype=int)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'subsample_for_bin': hp.choice('subsample_for_bin', [20000, 30000, 40000]),\n",
    "    'min_data_in_leaf': hp.choice('min_data_in_leaf', np.arange(20, 500, 5, dtype=int)),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b28e0f44949c214b07e3ae57e8c231514c71edc5"
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "x, y = process_data(market_obs, news_obs)\n",
    "t1 = time.time()\n",
    "totalTime = t1-t0\n",
    "\n",
    "print('Took',totalTime,'to process data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bbf80c82d1b2467ba7671e1bfa4ad61a1beafe2e"
   },
   "outputs": [],
   "source": [
    "# IGNORE HYPERTUNING FOR NOW.\n",
    "# https://towardsdatascience.com/automated-machine-learning-hyperparameter-tuning-in-python-dfda59b72f8a\n",
    "'''\n",
    "def objective(params, n_folds = 5):\n",
    "    # n-fold CV with hyperparameters; early stopping based on ROC/AUC\n",
    "    cv_results = lgb.cv(params, train, nfold = n_folds, num_boost_round = 500,\n",
    "                        early_stopping_rounds = 100, metrics = 'auc', seed = 42,\n",
    "                        stratified = False, shuffle = False)\n",
    "    best_score = max(cv_results['auc-mean'])\n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    pbar.update()\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "MAX_EVALS = 10\n",
    "pbar = tqdm(total=MAX_EVALS, desc=\"Hyperopt\")\n",
    "bayes_trials = Trials()\n",
    "bestParams = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "             max_evals = MAX_EVALS, trials = bayes_trials)\n",
    "pbar.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1b978c4f32ef6e22f5ec30727325dcca9c5ec53e"
   },
   "outputs": [],
   "source": [
    "# sanity check with R^2 on existing training dataset\n",
    "'''\n",
    "n_train = int(x.shape[0] * 0.8)\n",
    "trainX, trainY = x.iloc[:n_train], y.iloc[:n_train]\n",
    "testX, testY = x.iloc[n_train:], y.iloc[n_train:]\n",
    "\n",
    "model = lgb.train(lgb_params, train)\n",
    "prediction = model.predict(testX)\n",
    "prediction_score = r2_score(testY, prediction)\n",
    "print(prediction_score)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f48131de104f7c88d3e0fa83001cdafac8df211"
   },
   "outputs": [],
   "source": [
    "full_data = lgb.Dataset(x, y, categorical_feature=categorical_cols, free_raw_data=False)\n",
    "full_model = lgb.train(lgb_params, full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "598578e8fad5482bb4a14dd0c21391c6e228e582"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for (market_obs_df, news_obs_df, predictions_template_df) in env.get_prediction_days():\n",
    "    asset_codes = market_obs['assetCode'].append(market_obs_df['assetCode'])\n",
    "    newX = process_data(market_obs_df, news_obs_df, actual=True, all_asset_codes=asset_codes)\n",
    "    \n",
    "    newPrediction = full_model.predict(newX)\n",
    "    newPrediction = pd.concat([pd.Series(newPrediction), newX['assetCode']], axis=1)\n",
    "    predictions_template_df['assetCodeIndex'] = le.transform(predictions_template_df['assetCode'])\n",
    "    predictions_template_df = predictions_template_df.merge(newPrediction, left_on='assetCodeIndex', right_on='assetCode', how='outer')\n",
    "\n",
    "    predictions_template_df.drop(['confidenceValue', 'assetCodeIndex', 'assetCode_y'], axis=1, inplace=True)\n",
    "    predictions_template_df.columns = ['assetCode', 'confidenceValue']\n",
    "    env.predict(predictions_template_df)\n",
    "    \n",
    "    # update market_obs & news_obs\n",
    "    # but this will require having counter\n",
    "    i += 1\n",
    "    print(i)\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c8ed34ffb2c47c6e124530ec798c0b4eb01ddd5"
   },
   "outputs": [],
   "source": [
    "env.write_submission_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
